{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"S:/Capston/data2\"\n",
    "SAVE_FOLDER = \"S:/_tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series_meta_df = pd.read_csv(os.path.join(data_dir,'train_series_meta.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series_meta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# # Write the list of .png files to a CSV file\n",
    "# with open(os.path.join(data_dir,\"images_file_name.csv\"), 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerows(list_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_img =os.listdir(os.path.join(data_dir,'train_images/'))\n",
    "series_meta_df = pd.read_csv(os.path.join(data_dir,'train_series_meta.csv'))                             \n",
    "lenght = series_meta_df.shape[0]     \n",
    "img_paths = []\n",
    "for index, row in series_meta_df.iterrows():\n",
    "    scans = []\n",
    "    patient = row[\"patient_id\"]\n",
    "    series = row[\"series_id\"]\n",
    "    pattern = \"^\" + str(int(patient)) + \"_\"+ str(int(series)) + \"_\"\n",
    "    series_img_list  = [file for file in list_img if bool(re.match(pattern, file))]\n",
    "    list_img = [file for file in list_img if file not in series_img_list ]\n",
    "    series_img_paths = [os.path.join(data_dir, 'train_images/') + file for file in series_img_list]\n",
    "    print(f\"{index+1} / {lenght}, images in series:{len(series_img_paths)}\", end='\\r')\n",
    "    img_paths.append(series_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# # Write the list of .png files to a CSV file\n",
    "# with open(os.path.join(data_dir,\"img_paths.csv\"), 'w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerows(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# # Define the path to the CSV file\n",
    "# csv_file_path = os.path.join(data_dir, \"img_paths.csv\")\n",
    "\n",
    "# # Initialize a list to store the data from the CSV file\n",
    "# img_paths = []\n",
    "\n",
    "# # Read the CSV file\n",
    "# with open(csv_file_path, 'r') as file:\n",
    "#     reader = csv.reader(file)\n",
    "#     for row in reader:\n",
    "#         img_paths.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Series_to_tensor(paths):\n",
    "    series_tensor = torch.zeros(store_res, store_res, len(paths))\n",
    "    for index, path in enumerate(paths):\n",
    "        image = Image.open(path)\n",
    "        image = np.array(image)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        #resize the 2d image \n",
    "        if image.shape != torch.Size([store_res, store_res]):\n",
    "            image = image.unsqueeze(0).unsqueeze(0)\n",
    "            image = F.interpolate(image, (store_res, store_res))\n",
    "            image = image.squeeze(0).squeeze(0)\n",
    "        series_tensor[:,:,index] = image\n",
    "\n",
    "    # Resize the 3d image along the vertical dimension.            \n",
    "    series_tensor = series_tensor.unsqueeze(0).unsqueeze(0)\n",
    "    series_tensor = F.interpolate(series_tensor, (store_res, store_res, store_res))\n",
    "    series_tensor = series_tensor.squeeze(0).squeeze(0)\n",
    "    return series_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining resolution\n",
    "store_res = 180\n",
    "Root = \"S:/Capston/data3\" \n",
    "# Iterate over rows with tqdm progress bar\n",
    "for index, row in tqdm(series_meta_df.iterrows(), total=len(series_meta_df)):\n",
    "    \n",
    "    patient = row[\"patient_id\"]\n",
    "    series = row[\"series_id\"]\n",
    "\n",
    "    series_tensor = Series_to_tensor(img_paths[index])\n",
    "    torch.save(series_tensor, os.path.join(Root, str(int(patient)) + '_' + str(int(series)) + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "Root = \"S:\\\\Capston\\\\data3\"\n",
    "series_meta_df[\"paths\"] = series_meta_df.apply(lambda row: os.path.join(Root, f\"{int(row['patient_id'])}_{int(row['series_id'])}.pt\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "series_meta_df = series_meta_df.merge(train_df, on='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = \"S:/Capston/data2/series_meta_plus_path.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "series_meta_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of patient_id as key and list of series as list\n",
    "\n",
    "# Group by 'patient' column and aggregate 'series' values into lists\n",
    "series_lists = series_meta_df.groupby('patient_id')['series_id'].agg(list)\n",
    "paths_lists = series_meta_df.groupby('patient_id')['paths'].agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths_lists[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_res = 128\n",
    "Root = \"S:/Capston/data3\" \n",
    "Root2 = \"S:/Capston/data4\"\n",
    "# Iterate over rows with tqdm progress bar\n",
    "for patient, series in tqdm(series_lists.items(), total=len(series_lists)):\n",
    "\n",
    "    # Create an empty list to store the tensors\n",
    "    tensor_list = []\n",
    "    for s in series:\n",
    "        # series_tensor = Series_to_tensor(img_paths[index])\n",
    "        series_tensor = torch.load(os.path.join(Root, str(int(patient)) + '_' + str(int(s)) + '.pt'))\n",
    "        tensor_list.append(series_tensor)\n",
    "    patient_tensor = np.concatenate(tensor_list, axis=2)\n",
    "    patient_tensor = torch.tensor(patient_tensor, dtype=torch.float32)\n",
    "\n",
    "    # checking tensor size and resize it if it was not in prper format\n",
    "    if patient_tensor.shape != torch.Size([store_res, store_res, store_res]):\n",
    "        patient_tensor = patient_tensor.unsqueeze(0).unsqueeze(0)\n",
    "        patient_tensor = F.interpolate(patient_tensor, (store_res, store_res, store_res))\n",
    "        patient_tensor = patient_tensor.squeeze(0).squeeze(0)\n",
    "\n",
    "    # Check the shape of the stacked tensors\n",
    "    torch.save(patient_tensor, os.path.join(Root2, str(int(patient)) + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_res = 128\n",
    "Root = \"S:/Capston/data3\" \n",
    "Root2 = \"S:/Capston/data4\"\n",
    "c = 0\n",
    "# Iterate over rows with tqdm progress bar\n",
    "for patient, paths in tqdm(paths_lists.items(), total=len(paths_lists)):\n",
    "    c += 1\n",
    "    merged_list = [element for sublist in paths for element in sublist]\n",
    "    print(len(paths[0]))\n",
    "    print(len(merged_list))\n",
    "    if c==5:\n",
    "        break\n",
    "    patient_tensor = Series_to_tensor(merged_list)\n",
    "    # Check the shape of the stacked tensors\n",
    "    torch.save(patient_tensor, os.path.join(Root2, str(int(patient)) + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making patients meta_data\n",
    "Root = \"S:\\\\Capston\\\\data4\"\n",
    "train_df[\"paths\"] = train_df.apply(lambda row: os.path.join(Root, f\"{int(row['patient_id'])}.pt\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patients_meta_df = patients_meta_df.merge(patients_meta_df,on='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "csv_file_path = \"S:/Capston/data2/patients_meta_plus_path.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "train_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "capstone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
